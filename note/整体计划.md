# 1) 背景（Background）

* 机器人/VLA 在真实场景执行任务前，需要把“任务文本 + 图像”压缩成**对动作规划真正有用的可视事实**。
* 以往描述冗长、带指令化语言、常把**任务文本当作事实**复制，导致：

  * 下游抓取/放置规划难以复用；
  * 评价难：真假混杂、不可复现；
  * 小模型能力受限，容易幻觉。
* 我们构建了“**Task Supplementor**”流水线：输入Image + Task → 输出**结构化可视事实**和一段简短补充文本。
* 运行时只用 **Qwen2.5-VL-3B**；**Qwen2.5-VL-72B** 作为**离线老师/裁判**（不进部署）；**LLaVA-v1.6-34B** 仅做**异构抽检**(为了防止Qwen同系列有数据缺陷从而及逆行抽检，用来确保Qwen2.5-VL-3B产出可信）。
* 指标：

  * **针对 Image 和 Task 生成的客观的 Description**：该 Description 只针对 Image 和 Task 进行客观内容的描述和补充，不进行额外的动作建议、不进行任何对VLA的action输出的指导。

---

# 2) 目的（Objectives）

**总体目标**

* 做一个**小而强**的补充器（Qwen-VL-3B）→ 提供**最小必要事实**给 OpenVLA/任意 VLA：
* 离线用 72B 老师 + 34B 抽检把 3B 的输出**蒸馏、对齐**，**不把大模型带进部署**，将Qwen2.5-VL-72B在agent方面的能力蒸馏给Qwen2.5-VL-3B，从而加强Qwen2.5-VL-3B这一领域的能力。
* 形成**可复用的数据与评测基准**：日志（jsonl）、表格（csv）、一致性工具、蒸馏样本构建脚本。
* 产出模型与实验数据需要写成一篇论文，投递目标为CVPR、ICCV、NIPS、ICLR、ICML等人工智能顶会。

**具体达成标准（阶段门）**

* 在 OpenVLA 使用的数据集Bridgedata v2上进行对照试验：1.单OpenVLA；2.OpenVLA+Qwen2.5-VL-3B（未蒸馏）；3.OpenVLA+无意义中性的字符的消融实验（确保有效性是因为内容而不是多了字符）；4.OpenVLA+Qwen2.5-VL-3B（有Qwen2.5-VL-72B蒸馏）。

---

# 3) 计划（Plan）

分三个阶段推进，每阶段都有可落地的脚本与产物。

**P1 调试Qwen2.5-VL-3B**

* 统一**可视事实**输出规范：只认视觉可证实内容；不复制任务文本到事实；确保Qwen2.5-VL-3B能够根据提示词生成格式稳定的Description（格式稳定是为了能更好的送入OpenVLA等VLA模型中）。

**P2 进行单OpenVLA实验、OpenVLA+Qwen2.5-VL-3B（未蒸馏）实验与OpenVLA+无意义中性的字符的消融实验**

* 目的1：打通Qwen2.5-VL-3B产出Description而后一并送入OpenVLA的流程；
* 目的2：进行单OpenVLA实验、OpenVLA+Qwen2.5-VL-3B（未蒸馏）与OpenVLA+无意义中性的字符的消融实验，为写论文准备数据。

**P3 蒸馏与最终实验落地**

* 用 Qwen2.5-VL-72B 作为老师，LLaVA-v1.6-34B作为检验裁判，结合Bridgedata v2训练集的数据，构建 **teacher-gold**；
* 使用teacher-gold来对Qwen2.5-VL-3B进行蒸馏，提升其能力；
* 做最终实验OpenVLA+Qwen2.5-VL-3B（有Qwen2.5-VL-72B蒸馏）；

---

# 4) 实验（Experiments）

**E0 OpenVLA基线复现**

接口方式：不加任何 supplement；环境、任务设定、评测脚本版本号（commit/conda env）写死。

**E1 Qwen2.5-VL-3B输出调试**

调试，并确保Qwen2.5-VL-3B能输出固定格式、有最大长度限制的Description（格式确定内容根据Image+Task生成即可） ，使其能稳定的传输给OpenVLA。

**E2 OpenVLA+Qwen2.5-VL-3B（未蒸馏）**

将Qwen2.5-VL-3B生成的Description连同Task一同送入OpenVLA的文本端。

**E3 OpenVLA+无意义中性的字符的消融实验**

设计为等长、无语义的占位串（如随机数字/常见英文停用词拼接），或打乱字段名但不包含任何可视的信息；
目的：证明收益来自内容而非“模型因为输入更长而‘更兴奋’”。

**E4 Qwen2.5-VL-72B 作为老师，LLaVA-v1.6-34B作为检验裁判，结合Bridgedata v2训练集的数据，构建 teacher-gold**


**E5 OpenVLA+Qwen2.5-VL-3B（有Qwen2.5-VL-72B蒸馏）**


---

# 5) 预期结果（Expected Outcomes）

**离线指标**

* 有了蒸馏后的Qwen2.5-VL-3B能显著提升OpenVLA性能。

**蒸馏数据**

* 构建出**高一致性**的 teacher-gold 集合，错误率低、可直接复现，方便开源。

**论文/开源可复现性**

* 完整的**脚本 + 指标 + 表格导出**流程

* 结论可以从“**更高的可证实率 + 更低的分歧**”与“**端到端任务成功率**”两条证据链共同支撑。

---





总结：

* 做一个**Task Supplementor**：用 **Qwen2.5-VL-3B**在运行时生成**仅基于 Image+Task 的、客观可证实的 Description**（最小必要事实，禁止动作建议/策略），作为任何 VLA（尤其 OpenVLA）的可插拔前置补充。
* **不把大模型进部署**：用 **Qwen2.5-VL-72B**做离线老师蒸馏，**LLaVA-v1.6-34B**做异构抽检与一致性校验，提升 3B 的稳健与可信。
* 形成**可复用基建**：统一输出规范，日志/表格/一致性工具/蒸馏样本脚本，可复现实验流水线，为论文与开源准备。
* **实验计划**：

  * **E0** 复现 OpenVLA 基线；
  * **E1** 调试 3B 的固定格式与长度受限的 Description；
  * **E2** OpenVLA+3B（未蒸馏）；
  * **E3** 等长**无语义占位串**消融，验证收益来自内容本身；
  * **E4** 基于 BridgeData v2 构建 **teacher-gold**（72B 教师+34B 裁判）；
  * **E5** OpenVLA+3B（蒸馏后）。
* **评测对象与对照**：在 **BridgeData v2** 上做 1) 纯 OpenVLA，2) OpenVLA+3B（未蒸馏），3) OpenVLA+等长无意义串，4) OpenVLA+3B（蒸馏）。
* **预期结果**：蒸馏后的 3B 明显提升 OpenVLA 成功率；产出高一致性的 teacher-gold 与**完整可复现脚本+指标+表格**，支撑论文投稿（CVPR/ICCV/NeurIPS/ICLR/ICML）。

